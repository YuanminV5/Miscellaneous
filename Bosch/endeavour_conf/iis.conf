input
{
	file
	{
		path => "C:/inetpub/logs/LogFiles/W3SVC1/*.log"
		start_position => "beginning"
		ignore_older => 604800
		
		# MUST HAVE FOR EACH INPUT
		add_field =>
		{ 
			"[@metadata][logtype]" => "iis_log"
			"[@metadata][configtype]" => "iis"
		}
	}
}

filter
{
	# Only apply this filter on input from this config file
	if [@metadata][configtype] == "iis"
	{
		# Ignore comments in log
		if [message] =~ "^#" 
		{
			# Extract fileds and set as csv columns
			if [message] =~ "^#Fields"
			{
				ruby
				{
					code => "
						fieldArray = event.get('message')
						fieldArray.slice!('#Fields: ')
						event.set('fields', fieldArray.split(' '))
					"
				}
				
				aggregate 
				{
					task_id => "%{path}"
					code => "map['fields'] = event.get('fields')"
				}
			}
				
			drop { }
		}

		# Apply patterns based on logtype
		if [@metadata][logtype] == "iis_log"
		{
			csv
			{
				separator => " "
				quote_char => "@"
			}
		}
			
		aggregate 
		{
			task_id => "%{path}"
			code => "event.set('fields', map['fields'])"
		}
		
		ruby
		{
			code => "
				fieldArray = event.get('fields')
				fieldArray.each_with_index {|val, index| columnx = 'column' + (index+1).to_s
					event.set(val, event.get(columnx))
					event.remove(columnx)
				}
			"
		}

		#Concat date and time field as timestamp
		mutate 
		{ 
			add_field => 
			{ 
				"timestamp" => "%{date} %{time}"
			}
		}

		# Using event timestamp as the logstash timestamp for the event
		date
		{
			match => [ "timestamp", "YYYY-MM-dd HH:mm:ss" ]
			timezone => "Etc/UTC"
		}

		mutate
		{ 
			add_field => { "[@metadata][esindex]" => "%{[@metadata][logtype]}_%{date}" }
			remove_field => [ "timestamp", "date", "time", "path", "message", "fields" ]
		}
	}
}

output
{
	if [@metadata][configtype] == "iis"
	{
		elasticsearch
		{
			hosts => [ "localhost:9200" ]
			index => "%{[@metadata][esindex]}"
		}
	}
}